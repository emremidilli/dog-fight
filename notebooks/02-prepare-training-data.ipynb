{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be93338c-9b67-48a5-8de4-220b40c09f1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf5a830-cd87-4bf2-9b16-cfb1edfc40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630c14d-89e6-4940-bb93-5924dbb395f9",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df14980-d3ea-414d-a2a4-20986df8e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.path.join('..', 'data', 'interim', 'version_01.csv')\n",
    "SCALER_DIR = os.path.join('..', 'data', 'scalers')\n",
    "OUTPUT_DIR = os.path.join('..', 'data', 'processed')\n",
    "GROUPS = ['record_id', 'aircraft_id']\n",
    "ACTIONS_FEATURES = [\n",
    "    'transform_matrix_0', 'transform_matrix_1', 'transform_matrix_2',\n",
    "    'transform_matrix_4', 'transform_matrix_5', 'transform_matrix_6',\n",
    "    'transform_matrix_8', 'transform_matrix_9', 'transform_matrix_10',\n",
    "    'brake_level']\n",
    "TEST_RATIO = 0.30\n",
    "RANDOM_STATE = 42\n",
    "LOOKBACK_LAG = 10\n",
    "FORECAST_LAG = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83404c4a-2447-413a-8ed4-50c82768583e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04604486-fd0d-4c18-a3a7-b6b2b9786300",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = pd.read_csv(INPUT_DIR, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e7a6c-fcce-428b-89be-918e84a6032d",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd18b0-ac67-4675-8e63-7e2fa91db490",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Calculate distances instead of positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbaa9562-bfd4-4638-a70f-4c7071c1c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = source.loc[:, 'transform_matrix_3'] - source.loc[:, 'transform_matrix_3_bandit']\n",
    "dy = source.loc[:, 'transform_matrix_7'] - source.loc[:, 'transform_matrix_7_bandit']\n",
    "dz = source.loc[:, 'transform_matrix_11'] - source.loc[:, 'transform_matrix_11_bandit']\n",
    "\n",
    "source.loc[:, 'horizontal_distance'] = np.sqrt(dx**2 + dz**2)\n",
    "\n",
    "source.drop(\n",
    "    columns=[\n",
    "        'transform_matrix_3', 'transform_matrix_3_bandit',\n",
    "        'transform_matrix_11', 'transform_matrix_11_bandit'],\n",
    "    inplace=True)\n",
    "\n",
    "source.rename(\n",
    "    columns={'transform_matrix_7': 'altitude', 'transform_matrix_7_bandit': 'altitude_bandit'},\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628096e-5ab1-4ecd-9b76-e48c7dc10ca1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Identify training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52879b28-cf3a-4d09-9fc1-db902cb67aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = source.groupby(GROUPS)\n",
    "\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "for name, df_0 in grouped:\n",
    "    df_0_train, df_0_test = train_test_split(df_0, test_size=TEST_RATIO, random_state=RANDOM_STATE)\n",
    "    train = pd.concat([train, df_0_train], ignore_index=True)\n",
    "    test = pd.concat([test, df_0_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10bb96e-f3b7-4f3b-ba67-b39e30b77c0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57a4a5b-1e54-447d-8708-7eb2b2d37b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_field_w_bandit(\n",
    "        df_train: pd.DataFrame,\n",
    "        df_test: pd.DataFrame,\n",
    "        cols: list,\n",
    "        name: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    '''\n",
    "    normalizes a field based on both our and bandit aircraft.\n",
    "    saves the scaler.\n",
    "    returns the normalized dataframe\n",
    "    '''\n",
    "\n",
    "    # identify values to calculate stats\n",
    "    all_fields = tuple()\n",
    "    for col in cols:\n",
    "        all_fields = all_fields + (df_train.loc[:, [col]].to_numpy(), )\n",
    "        all_fields = all_fields + (df_train.loc[:, [f'{col}_bandit']].to_numpy(), )\n",
    "\n",
    "    all_values = np.concatenate(all_fields)\n",
    "\n",
    "    # fit\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(all_values)\n",
    "\n",
    "    for col in cols:\n",
    "        # transform\n",
    "        df_train.loc[:, [col]] = scaler\\\n",
    "            .transform(df_train.loc[:, [col]].to_numpy())\n",
    "        \n",
    "        df_train.loc[:, [f'{col}_bandit']] = scaler\\\n",
    "            .transform(df_train.loc[:, [f'{col}_bandit']].to_numpy())\n",
    "    \n",
    "        df_test.loc[:, [col]] = scaler\\\n",
    "            .transform(df_test.loc[:, [col]].to_numpy())\n",
    "        \n",
    "        df_test.loc[:, [f'{col}_bandit']] = scaler\\\n",
    "            .transform(df_test.loc[:, [f'{col}_bandit']].to_numpy())\n",
    "\n",
    "    # save scaler\n",
    "    joblib.dump(scaler, os.path.join(SCALER_DIR, f'{name}.pkl'))\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471d1f69-2e5a-4c65-8392-99c5abbc23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = normalize_field_w_bandit(train, test, ['altitude'], 'altitude')\n",
    "train, test = normalize_field_w_bandit(train, test, ['velocity_x', 'velocity_y', 'velocity_z'], 'velocity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6db511-462e-450c-9afe-a83213d9e338",
   "metadata": {},
   "source": [
    "## Produce lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad511b7-5fc4-4248-a6ca-c0d56d5bedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lookback_lags(df: pd.DataFrame, features: list) -> np.array:\n",
    "    lookback_steps = range(-LOOKBACK_LAG, 0)\n",
    "    data = df\\\n",
    "        .loc[:, features]\\\n",
    "        .to_numpy()\n",
    "    \n",
    "    lb = np.zeros((\n",
    "        len(data),\n",
    "        len(lookback_steps),\n",
    "        len(features)))\n",
    "    for i, _ in enumerate(features):\n",
    "        cov = data[:, i]\n",
    "        for j, shift in enumerate(lookback_steps):\n",
    "            lb[:, j, i] = np.roll(cov, shift=abs(shift))\n",
    "    return lb\n",
    "\n",
    "\n",
    "def get_forecast_lags(df: pd.DataFrame, features: list) -> np.array:\n",
    "    forecast_steps = range(0, FORECAST_LAG)\n",
    "    data = df\\\n",
    "        .loc[:, features]\\\n",
    "        .to_numpy()\n",
    "    \n",
    "    fc = np.zeros((\n",
    "        len(data),\n",
    "        len(forecast_steps),\n",
    "        len(features)))\n",
    "    for i, _ in enumerate(features):\n",
    "        cov = data[:, i]\n",
    "        for j, shift in enumerate(forecast_steps):\n",
    "            fc[:, j, i] = np.roll(cov, shift=abs(shift))\n",
    "    return fc\n",
    "\n",
    "\n",
    "def produce_input_and_labels(data: pd.DataFrame):\n",
    "    grouped = data.groupby(GROUPS)\n",
    "    \n",
    "    list_lb_state_our = []\n",
    "    list_lb_state_bandit = []\n",
    "    list_fc_state_our = []\n",
    "    list_fc_state_bandit = []\n",
    "    list_fc_action_our = []\n",
    "    for name, df_0 in grouped:\n",
    "        df_0.drop(columns=['aircraft_id', 'record_id', 'timestep'], inplace=True)\n",
    "    \n",
    "        bandit_features = [col for col in df_0.columns if col.endswith('_bandit')]\n",
    "        our_features = [col for col in df_0.columns if not col.endswith('_bandit')]\n",
    "   \n",
    "        lb_state_our = get_lookback_lags(df=df_0, features=our_features)\n",
    "        lb_state_bandit = get_lookback_lags(df=df_0, features=bandit_features)\n",
    "    \n",
    "        fc_state_our = get_forecast_lags(df=df_0, features=our_features)\n",
    "        fc_state_bandit = get_forecast_lags(df=df_0, features=bandit_features)\n",
    "    \n",
    "        fc_action_our = get_forecast_lags(df=df_0, features=ACTIONS_FEATURES)\n",
    "    \n",
    "        cut_start = LOOKBACK_LAG\n",
    "        lb_state_our = lb_state_our[cut_start:]\n",
    "        lb_state_bandit = lb_state_bandit[cut_start:]\n",
    "        fc_state_our = fc_state_our[cut_start:]\n",
    "        fc_state_bandit = fc_state_bandit[cut_start:]\n",
    "        fc_action_our = fc_action_our[cut_start:]\n",
    "    \n",
    "        cut_end = (FORECAST_LAG - 1) * -1\n",
    "        lb_state_our = lb_state_our[:cut_end]\n",
    "        lb_state_bandit = lb_state_bandit[:cut_end]\n",
    "        fc_state_our = fc_state_our[:cut_end]\n",
    "        fc_state_bandit = fc_state_bandit[:cut_end]\n",
    "        fc_action_our = fc_action_our[:cut_end]\n",
    "    \n",
    "        list_lb_state_our.append(lb_state_our)\n",
    "        list_lb_state_bandit.append(lb_state_bandit)\n",
    "        list_fc_state_our.append(fc_state_our)\n",
    "        list_fc_state_bandit.append(fc_state_bandit)\n",
    "        list_fc_action_our.append(fc_action_our)\n",
    "    \n",
    "    final_lb_state_our = np.concatenate(list_lb_state_our, axis=0)\n",
    "    final_lb_state_bandit = np.concatenate(list_lb_state_bandit, axis=0)\n",
    "    final_fc_state_our = np.concatenate(list_fc_state_our, axis=0)\n",
    "    final_fc_state_bandit = np.concatenate(list_fc_state_bandit, axis=0)\n",
    "    final_fc_action_our = np.concatenate(list_fc_action_our, axis=0)\n",
    "\n",
    "    inputs = (final_lb_state_our, final_lb_state_bandit, final_fc_action_our)\n",
    "    labels = (final_fc_state_our, final_fc_state_bandit)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d1e724-508c-4a57-8dac-ccd41417fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = produce_input_and_labels(train)\n",
    "test_X, test_Y = produce_input_and_labels(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc069f-65b9-4af4-b44e-47e7065df16b",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce63ce90-5718-4560-8afc-fa8db0044781",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ds in enumerate(['final_lb_state_our', 'final_lb_state_bandit', 'final_fc_action_our']):\n",
    "    np.save(os.path.join(OUTPUT_DIR, f'train_{ds}.npy'), train_X[i])\n",
    "    np.save(os.path.join(OUTPUT_DIR, f'test_{ds}.npy'), test_X[i])\n",
    "\n",
    "for i, ds in enumerate(['final_fc_state_our', 'final_fc_state_bandit']):\n",
    "    np.save(os.path.join(OUTPUT_DIR, f'train_{ds}.npy'), train_Y[i])\n",
    "    np.save(os.path.join(OUTPUT_DIR, f'test_{ds}.npy'), test_Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e1e1762-09e0-48df-9657-05c3a1f28479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aircraft_id', 'record_id', 'timestep', 'health_level', 'brake_level',\n",
       "       'flaps_level', 'transform_matrix_0', 'transform_matrix_1',\n",
       "       'transform_matrix_2', 'transform_matrix_4', 'transform_matrix_5',\n",
       "       'transform_matrix_6', 'altitude', 'transform_matrix_8',\n",
       "       'transform_matrix_9', 'transform_matrix_10', 'velocity_x', 'velocity_y',\n",
       "       'velocity_z', 'bandit_is_targetted', 'transform_matrix_0_bandit',\n",
       "       'transform_matrix_1_bandit', 'transform_matrix_2_bandit',\n",
       "       'transform_matrix_4_bandit', 'transform_matrix_5_bandit',\n",
       "       'transform_matrix_6_bandit', 'altitude_bandit',\n",
       "       'transform_matrix_8_bandit', 'transform_matrix_9_bandit',\n",
       "       'transform_matrix_10_bandit', 'velocity_x_bandit', 'velocity_y_bandit',\n",
       "       'velocity_z_bandit', 'horizontal_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
