{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46a760f-c662-45fe-a0e6-711d8fc7a499",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534de7b4-17d6-40df-96b9-02ed625edcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641370d-4014-4730-96d3-362a62e1a467",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d58e42-6d9e-484f-98b0-9f3cedac7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.path.join('..', 'data', 'processed')\n",
    "MODEL_DIR = os.path.join('..', 'models')\n",
    "MODEL_VERSION = 'v01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32f68f-7c12-43e2-a068-d177f12832b6",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698748b-20de-4063-ab36-a5fff8d24dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aecdf5-0ab4-4bac-b0f7-7f0a9aa91f04",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f707bf9-a145-4819-b1c9-8c2cd63c234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombatForecastDataset(Dataset):\n",
    "    def __init__(self, path_lb_our, path_lb_bandit, path_fc_action, path_fc_our, path_fc_bandit, sos_value=9999.0):\n",
    "        self.lb_our = np.load(path_lb_our)          # (N, 10, 18)\n",
    "        self.lb_bandit = np.load(path_lb_bandit)    # (N, 10, 13)\n",
    "        self.fc_action = np.load(path_fc_action)    # (N, 3, 10)\n",
    "        self.fc_our = np.load(path_fc_our)          # (N, 3, 18)\n",
    "        self.fc_bandit = np.load(path_fc_bandit)    # (N, 3, 13)\n",
    "        self.sos_value = sos_value\n",
    "        self.nr_of_padding = self.lb_our.shape[-1] - self.lb_bandit.shape[-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lb_our)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lb_our = self.lb_our[idx]         # (10, 18)\n",
    "        lb_bandit = self.lb_bandit[idx]   # (10, 13)\n",
    "    \n",
    "        # Pad lb_bandit to (10, 18)\n",
    "        pad_width = ((0, 0), (0, self.nr_of_padding))  # pad 5 columns (features) at the end\n",
    "        lb_bandit_padded = np.pad(lb_bandit, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "        # Now both are (10, 18) â†’ stack along time axis (axis=0)\n",
    "        src = np.concatenate([lb_our, lb_bandit_padded], axis=0)  # (20, 18)\n",
    "    \n",
    "        # Decoder input\n",
    "        tgt = self.fc_action[idx]  # (3, 10)\n",
    "        sos = np.ones((1, tgt.shape[1])) * self.sos_value\n",
    "        tgt_input = np.vstack([sos, tgt[:-1]])  # (3, 10)\n",
    "\n",
    "        # Target output\n",
    "        tgt_output = np.concatenate([self.fc_our[idx], self.fc_bandit[idx]], axis=-1)  # (3, 31)\n",
    "    \n",
    "        return (\n",
    "            torch.tensor(src, dtype=torch.float32),        # encoder input (20, 18)\n",
    "            torch.tensor(tgt_input, dtype=torch.float32),  # decoder input (3, 10)\n",
    "            torch.tensor(tgt_output, dtype=torch.float32)  # decoder target (3, 31)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912384c-ee65-4a1b-ae9e-c81c971c457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CombatForecastDataset(\n",
    "    os.path.join(INPUT_DIR, 'train_lb_state_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'train_lb_state_bandit.npy'),\n",
    "    os.path.join(INPUT_DIR, 'train_fc_action_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'train_fc_state_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'train_fc_state_bandit.npy'),\n",
    "    sos_value=0)\n",
    "\n",
    "testing_dataset = CombatForecastDataset(\n",
    "    os.path.join(INPUT_DIR, 'test_lb_state_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'test_lb_state_bandit.npy'),\n",
    "    os.path.join(INPUT_DIR, 'test_fc_action_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'test_fc_state_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'test_fc_state_bandit.npy'),\n",
    "    sos_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d1deb-14b9-4179-81d0-0aef76b6bb84",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570dcebd-ffa2-4660-8dc8-922c858d1db5",
   "metadata": {},
   "source": [
    "## UDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c63c89-2a3e-4589-9b0c-b5cd32394eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastTransformer(nn.Module):\n",
    "    def __init__(self, enc_input_dim=18, dec_input_dim=10, out_dim=31,\n",
    "                 d_model=256, nhead=4, num_encoder_layers=3, num_decoder_layers=3,\n",
    "                 dim_feedforward=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Project encoder and decoder inputs to d_model\n",
    "        self.encoder_input_proj = nn.Linear(enc_input_dim, d_model)\n",
    "        self.decoder_input_proj = nn.Linear(dec_input_dim, d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "        # Transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # Output projection to target dimension\n",
    "        self.output_proj = nn.Linear(d_model, out_dim)\n",
    "\n",
    "    def forward(self, src, tgt_input, tgt_mask=None):\n",
    "        # src: (batch, src_seq_len, enc_input_dim)\n",
    "        # tgt_input: (batch, tgt_seq_len, dec_input_dim)\n",
    "\n",
    "        src = self.encoder_input_proj(src) * math.sqrt(self.d_model)  # (batch, 20, d_model)\n",
    "        tgt = self.decoder_input_proj(tgt_input) * math.sqrt(self.d_model)  # (batch, 3, d_model)\n",
    "\n",
    "        src = self.positional_encoding(src).transpose(0, 1)  # (20, batch, d_model)\n",
    "        tgt = self.positional_encoding(tgt).transpose(0, 1)  # (3, batch, d_model)\n",
    "\n",
    "        out = self.transformer(src, tgt, tgt_mask=tgt_mask)  # (3, batch, d_model)\n",
    "        out = self.output_proj(out.transpose(0, 1))  # (batch, 3, out_dim)\n",
    "\n",
    "        return out\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)  # correctly handled across devices\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Automatically move self.pe to same device as x\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f918d5-fc71-4c6a-95ff-91bde125eaf2",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56869e-b5bc-41a3-a4b4-6c2bd56e7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(training_dataset, batch_size=128, shuffle=True)\n",
    "test_data_loader = DataLoader(testing_dataset, batch_size=128, shuffle=True)\n",
    "model = ForecastTransformer(\n",
    "    enc_input_dim=15,\n",
    "    dec_input_dim=9,\n",
    "    out_dim=6,\n",
    "    d_model=256,\n",
    "    nhead=4,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    dim_feedforward=512,\n",
    "    dropout=0.1)\\\n",
    "    .to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f17f1-2ee2-4da9-b35c-132f23f6722c",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2663a-78da-413e-a56b-914f1f93c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10  # number of epochs without improvement before stopping\n",
    "best_val_loss = float('inf')  # initially, the best validation loss is infinite\n",
    "epochs_without_improvement = 0  # to count how many epochs without improvement\n",
    "start_after = 200\n",
    "# Prevent model from seeing future tokens during training\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones((sz, sz)) * float('-inf'), diagonal=1)\n",
    "    \n",
    "for epoch in tqdm(range(1000)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt_input, tgt_output in train_data_loader:\n",
    "        src, tgt_input, tgt_output = src.to(device), tgt_input.to(device), tgt_output.to(device)\n",
    "\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n",
    "\n",
    "        pred = model(src, tgt_input, tgt_mask)\n",
    "        loss = criterion(pred, tgt_output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt_input, tgt_output in test_data_loader:\n",
    "            src, tgt_input, tgt_output = src.to(device), tgt_input.to(device), tgt_output.to(device)\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n",
    "            pred = model(src, tgt_input, tgt_mask)\n",
    "            loss = criterion(pred, tgt_output)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_data_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {total_loss / len(train_data_loader):.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if epoch <= start_after:\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'{MODEL_VERSION}.pth'))\n",
    "        continue\n",
    "        \n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'{MODEL_VERSION}.pth'))  # Save model weights\n",
    "        print(f\"Model saved with validation loss: {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Stop training if the patience is exceeded\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping after epoch {epoch+1} due to no improvement in validation loss.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e892096-2fde-42c0-8019-2c2e6c72e0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
