{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46a760f-c662-45fe-a0e6-711d8fc7a499",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534de7b4-17d6-40df-96b9-02ed625edcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641370d-4014-4730-96d3-362a62e1a467",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d58e42-6d9e-484f-98b0-9f3cedac7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = os.path.join('..', 'data', 'processed')\n",
    "MODEL_DIR = os.path.join('..', 'models')\n",
    "MODEL_VERSION = 'v01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32f68f-7c12-43e2-a068-d177f12832b6",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e698748b-20de-4063-ab36-a5fff8d24dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aecdf5-0ab4-4bac-b0f7-7f0a9aa91f04",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f707bf9-a145-4819-b1c9-8c2cd63c234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombatForecastDataset(Dataset):\n",
    "    def __init__(self, path_lb_our, path_lb_bandit, path_fc_action, path_fc_our, path_fc_bandit):\n",
    "        self.lb_our = np.load(path_lb_our)\n",
    "        self.lb_bandit = np.load(path_lb_bandit)\n",
    "        self.fc_action = np.load(path_fc_action)\n",
    "        self.fc_our = np.load(path_fc_our)\n",
    "        self.fc_bandit = np.load(path_fc_bandit)\n",
    "        self.nr_of_padding = self.lb_our.shape[-1] - self.lb_bandit.shape[-1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lb_our)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lb_our = self.lb_our[idx]\n",
    "        lb_bandit = self.lb_bandit[idx]\n",
    "    \n",
    "        pad_width = ((0, 0), (0, self.nr_of_padding))\n",
    "        lb_bandit_padded = np.pad(lb_bandit, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "        src = np.concatenate([lb_our, lb_bandit_padded], axis=0)\n",
    "        \n",
    "        # Decoder input\n",
    "        # tgt_input = self.fc_action[idx]\n",
    "        dec_beg = self.lb_bandit[idx][[-1], [3, 7, 11]]\n",
    "        tgt_input = self.fc_bandit[idx]\n",
    "        tgt_input = np.vstack([dec_beg, tgt_input[:-1]])\n",
    "\n",
    "        # Target output\n",
    "        tgt_output = self.fc_bandit[idx]\n",
    "    \n",
    "        return (\n",
    "            torch.tensor(src, dtype=torch.float32),\n",
    "            torch.tensor(tgt_input, dtype=torch.float32),\n",
    "            torch.tensor(tgt_output, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9912384c-ee65-4a1b-ae9e-c81c971c457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CombatForecastDataset(\n",
    "    os.path.join(INPUT_DIR, 'train_lb_state_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'train_lb_state_bandit.npy'),\n",
    "    os.path.join(INPUT_DIR, 'train_fc_action_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'train_fc_state_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'train_fc_state_bandit.npy'))\n",
    "\n",
    "testing_dataset = CombatForecastDataset(\n",
    "    os.path.join(INPUT_DIR, 'test_lb_state_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'test_lb_state_bandit.npy'),\n",
    "    os.path.join(INPUT_DIR, 'test_fc_action_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'test_fc_state_our.npy'),\n",
    "    os.path.join(INPUT_DIR, 'test_fc_state_bandit.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d1deb-14b9-4179-81d0-0aef76b6bb84",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570dcebd-ffa2-4660-8dc8-922c858d1db5",
   "metadata": {},
   "source": [
    "## UDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c63c89-2a3e-4589-9b0c-b5cd32394eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastTransformer(nn.Module):\n",
    "    def __init__(self, enc_input_dim=18, dec_input_dim=10, out_dim=31,\n",
    "                 d_model=256, nhead=4, num_encoder_layers=3, num_decoder_layers=3,\n",
    "                 dim_feedforward=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Project encoder and decoder inputs to d_model\n",
    "        self.encoder_input_proj = nn.Linear(enc_input_dim, d_model)\n",
    "        self.decoder_input_proj = nn.Linear(dec_input_dim, d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "\n",
    "        # Transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # Output projection to target dimension\n",
    "        self.output_proj = nn.Linear(d_model, out_dim)\n",
    "\n",
    "    def forward(self, src, tgt_input, tgt_mask=None):\n",
    "        # src: (batch, src_seq_len, enc_input_dim)\n",
    "        # tgt_input: (batch, tgt_seq_len, dec_input_dim)\n",
    "\n",
    "        src = self.encoder_input_proj(src) * math.sqrt(self.d_model)  # (batch, 20, d_model)\n",
    "        tgt = self.decoder_input_proj(tgt_input) * math.sqrt(self.d_model)  # (batch, 3, d_model)\n",
    "\n",
    "        src = self.positional_encoding(src).transpose(0, 1)  # (20, batch, d_model)\n",
    "        tgt = self.positional_encoding(tgt).transpose(0, 1)  # (3, batch, d_model)\n",
    "\n",
    "        out = self.transformer(src, tgt, tgt_mask=tgt_mask)  # (3, batch, d_model)\n",
    "        out = self.output_proj(out.transpose(0, 1))  # (batch, 3, out_dim)\n",
    "\n",
    "        return out\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)  # correctly handled across devices\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Automatically move self.pe to same device as x\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f918d5-fc71-4c6a-95ff-91bde125eaf2",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c56869e-b5bc-41a3-a4b4-6c2bd56e7c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_data_loader = DataLoader(training_dataset, batch_size=128, shuffle=True)\n",
    "test_data_loader = DataLoader(testing_dataset, batch_size=128, shuffle=True)\n",
    "model = ForecastTransformer(\n",
    "    enc_input_dim=15,\n",
    "    dec_input_dim=3,\n",
    "    out_dim=3,\n",
    "    d_model=256,\n",
    "    nhead=4,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    dim_feedforward=512,\n",
    "    dropout=0.1)\\\n",
    "    .to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f17f1-2ee2-4da9-b35c-132f23f6722c",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2663a-78da-413e-a56b-914f1f93c472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 1/1000 [00:35<9:44:46, 35.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.0892, Validation Loss: 0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 2/1000 [01:09<9:37:56, 34.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 0.0119, Validation Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 3/1000 [01:48<10:07:38, 36.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 0.0036, Validation Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 4/1000 [02:24<10:04:16, 36.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 0.0020, Validation Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 5/1000 [03:01<10:07:03, 36.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 0.0013, Validation Loss: 0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 6/1000 [03:36<9:59:27, 36.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 0.0011, Validation Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 7/1000 [04:11<9:52:23, 35.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 0.0009, Validation Loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 8/1000 [04:46<9:45:50, 35.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 0.0007, Validation Loss: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 9/1000 [05:21<9:41:15, 35.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 0.0006, Validation Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 10/1000 [05:55<9:38:07, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 0.0006, Validation Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 11/1000 [06:30<9:35:18, 34.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Training Loss: 0.0005, Validation Loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 12/1000 [07:05<9:33:22, 34.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Training Loss: 0.0005, Validation Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 13/1000 [07:39<9:31:26, 34.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Training Loss: 0.0004, Validation Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1% 14/1000 [08:17<9:45:05, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Training Loss: 0.0004, Validation Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 15/1000 [08:52<9:44:04, 35.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Training Loss: 0.0004, Validation Loss: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 16/1000 [09:27<9:38:52, 35.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Training Loss: 0.0004, Validation Loss: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 17/1000 [10:01<9:34:36, 35.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Training Loss: 0.0003, Validation Loss: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% 18/1000 [10:36<9:33:13, 35.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Training Loss: 0.0003, Validation Loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "patience = 10  # number of epochs without improvement before stopping\n",
    "best_val_loss = float('inf')  # initially, the best validation loss is infinite\n",
    "epochs_without_improvement = 0  # to count how many epochs without improvement\n",
    "start_after = 200\n",
    "# Prevent model from seeing future tokens during training\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    return torch.triu(torch.ones((sz, sz)) * float('-inf'), diagonal=1)\n",
    "    \n",
    "for epoch in tqdm(range(1000)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt_input, tgt_output in train_data_loader:\n",
    "        src, tgt_input, tgt_output = src.to(device), tgt_input.to(device), tgt_output.to(device)\n",
    "\n",
    "        tgt_mask = generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n",
    "\n",
    "        pred = model(src, tgt_input, tgt_mask)\n",
    "        loss = criterion(pred, tgt_output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt_input, tgt_output in test_data_loader:\n",
    "            src, tgt_input, tgt_output = src.to(device), tgt_input.to(device), tgt_output.to(device)\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n",
    "            pred = model(src, tgt_input, tgt_mask)\n",
    "            loss = criterion(pred, tgt_output)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_data_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {total_loss / len(train_data_loader):.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if epoch <= start_after:\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'{MODEL_VERSION}.pth'))\n",
    "        continue\n",
    "        \n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'{MODEL_VERSION}.pth'))  # Save model weights\n",
    "        print(f\"Model saved with validation loss: {avg_val_loss:.4f}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    # Stop training if the patience is exceeded\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping after epoch {epoch+1} due to no improvement in validation loss.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e892096-2fde-42c0-8019-2c2e6c72e0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
